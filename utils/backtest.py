# utils/backtest.py
# ğŸ“Œ TTL ì „ëµ ë°±í…ŒìŠ¤íŠ¸ìš© í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ ì •ì˜

import requests
import pandas as pd
import numpy as np
from datetime import timedelta
from datetime import datetime
import pytz
import os
import pandas as pd
import pandas as pd
import os
from utils.recommend import calculate_roc

TIINGO_API_KEY = "87f8380c68d1ae98523f90aa602a84b12a9e7483"  # ğŸ‘‰ Tiingo ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ ì…ë ¥

# API_KEYS = ["ONB35B97BRJ6G3T8", "AP68Y6LGDXSHYQEP"]
# # API í‚¤ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì¸ë±ìŠ¤
# api_key_index = 0

# í•œêµ­ ì‹œê°„ ì„¤ì • (UTC+9)
KST = pytz.timezone('Asia/Seoul')

# CALL_COUNT = 0
# MAX_CALLS_PER_DAY = 490  # Alpha Vantage ë¬´ë£Œ í”Œëœ ê¸°ì¤€ (ì—¬ìœ  í¬í•¨)

# def get_next_api_key():
#     global api_key_index
#     api_key_index = (api_key_index + 1) % len(API_KEYS)
#     return API_KEYS[api_key_index]

# def check_api_quota():
#     global CALL_COUNT
#     CALL_COUNT += 1
#     print(f"ğŸ“ˆ API í˜¸ì¶œ ì¹´ìš´íŠ¸: {CALL_COUNT}/{MAX_CALLS_PER_DAY}")
#     if CALL_COUNT > MAX_CALLS_PER_DAY:
#         raise RuntimeError("ğŸ“› Alpha Vantage ì¼ì¼ í˜¸ì¶œ í•œë„ ì´ˆê³¼. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        
def is_range_cached(start_dt, end_dt, df):
    if "date" not in df.columns or df.empty:
        return False
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"])
    if df.empty:
        return False
    min_cached = df["date"].min()
    max_cached = df["date"].max()

    # ğŸ” ë¡œê·¸ë¡œ í™•ì¸
    print(f"ğŸ” ìºì‹œ ë²”ìœ„: {min_cached.date()} ~ {max_cached.date()}")
    print(f"ğŸ“… ìš”ì²­ ë²”ìœ„: {start_dt.date()} ~ {end_dt.date()}")

    return start_dt >= min_cached and end_dt <= max_cached
    
def calculate_rsi(series: pd.Series, period: int = 14) -> pd.Series:
    delta = series.diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)

    avg_gain = gain.ewm(alpha=1/period, min_periods=period, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/period, min_periods=period, adjust=False).mean()

    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

def get_price_data(symbol: str, start: str, end: str) -> pd.DataFrame:
    cache_dir = "cache"
    os.makedirs(cache_dir, exist_ok=True)

    cache_file = os.path.join(cache_dir, f"{symbol}.csv")
    last_download_file = os.path.join(cache_dir, f"{symbol}_last_downloaded.txt")

    # âœ… ìºì‹œ ë¡œë“œ
    if os.path.exists(cache_file):
        cached_df = pd.read_csv(cache_file, parse_dates=["date"])
        cached_df["date"] = pd.to_datetime(cached_df["date"]).dt.date  # tz ì œê±° ë° .dateë¡œ í†µì¼
    else:
        cached_df = pd.DataFrame(columns=["date", "close", "open", "high", "low", "volume"])

    # âœ… ë§ˆì§€ë§‰ ë‹¤ìš´ë¡œë“œ ë‚ ì§œ ë¡œë“œ
    if os.path.exists(last_download_file):
        with open(last_download_file, "r") as f:
            last_downloaded_date = pd.to_datetime(f.read().strip()).date()
    else:
        last_downloaded_date = None

    # âœ… ìš”ì²­ ë²”ìœ„ ì²˜ë¦¬
    start_dt = pd.to_datetime(start).date()
    end_dt = pd.to_datetime(end).date()

    # âœ… ìºì‹œ ë²”ìœ„ í¬í•¨ ì—¬ë¶€ íŒë‹¨
    if not cached_df.empty:
        min_cached = min(cached_df["date"])
        max_cached = max(cached_df["date"])
        range_cached = (start_dt >= min_cached) and (end_dt <= max_cached)
    else:
        range_cached = False

    # âœ… ë””ë²„ê¹… ì¶œë ¥
    print(f"ğŸ” range_cached = {range_cached}")
    print(f"ğŸ“… last_downloaded_date = {last_downloaded_date}")
    print(f"ğŸ“… end_dt = {end_dt}")

    # âœ… ë‹¤ìš´ë¡œë“œ ì¡°ê±´: ìºì‹œ ë²”ìœ„ ë¶€ì¡± + ë§ˆì§€ë§‰ ë‹¤ìš´ë¡œë“œ ê¸°ë¡ ë¯¸ë‹¬
    if not range_cached and (last_downloaded_date is None or last_downloaded_date != end_dt):
        print("ğŸŒ Tiingoì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

        url = f"https://api.tiingo.com/tiingo/daily/{symbol}/prices"
        headers = {"Content-Type": "application/json"}
        params = {
            "token": TIINGO_API_KEY,
            "startDate": "2010-01-01",  # ì „ì²´ ë°ì´í„° ìš”ì²­
            "resampleFreq": "daily"
        }

        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
        except Exception as e:
            print(f"âŒ Tiingo ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

        df = pd.DataFrame(data)
        df["date"] = pd.to_datetime(df["date"]).dt.date  # tz ì œê±° í›„ date íƒ€ì… ë³€í™˜
                        
        # adjCloseê°€ ì—†ëŠ”ì§€ í™•ì¸
        if "adjClose" not in df.columns or df["adjClose"].isnull().all():
            print(f"âš ï¸ {symbol} ì€ adjClose(ì¡°ì • ì¢…ê°€)ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        df = df.rename(columns={
            "adjClose": "close",
            "adjOpen": "open",
            "adjHigh": "high",
            "adjLow": "low",
            "adjVolume": "volume"
        })
        
        df = df.loc[:, ~df.columns.duplicated(keep="first")]

        df = df[["date", "close", "open", "high", "low", "volume"]].sort_values("date")
        
        # ë³‘í•© ì „ì— ì—´ ì´ë¦„ ì •ë¦¬
        expected_columns = ["date", "close", "open", "high", "low", "volume"]

        # í•„í„°ë§í•˜ì—¬ í•„ìš”í•œ ì—´ë§Œ ìœ ì§€
        df = df[[col for col in expected_columns if col in df.columns]]
        cached_df = cached_df[[col for col in expected_columns if col in cached_df.columns]]

        # ì—´ ì´ë¦„ ê°•ì œ ì„¤ì • (í˜¹ì‹œë¼ë„ NaN ìˆì„ ê²½ìš° ëŒ€ë¹„)
        df.columns = expected_columns[:df.shape[1]]
        cached_df.columns = expected_columns[:cached_df.shape[1]]
        
        # âœ… ìºì‹œ ë³‘í•© ë° ì €ì¥
        cached_df = pd.concat([cached_df, df], ignore_index=True)
        cached_df = cached_df.drop_duplicates(subset="date").sort_values("date")
        cached_df.to_csv(cache_file, index=False)

        # âœ… ë‹¤ìš´ë¡œë“œ ê¸°ë¡ ê°±ì‹ 
        with open(last_download_file, "w") as f:
            f.write(str(end_dt))

        print(f"âœ… ë³‘í•©ëœ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_file}")

    # âœ… ìš”ì²­ êµ¬ê°„ í•„í„°ë§
    result_df = cached_df[
        (cached_df["date"] >= start_dt) & (cached_df["date"] <= end_dt)
    ].copy()

    # âœ… ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    result_df['ma20'] = result_df['close'].rolling(window=20).mean()
    result_df['ma60'] = result_df['close'].rolling(window=60).mean()
    result_df["ê¸°ìš¸ê¸°"] = ((result_df["ma20"] - result_df["ma20"].shift(10)) / result_df["ma20"].shift(10)) * 100
    result_df["ì •ë°°ì—´"] = (result_df["ma20"] > result_df["ma60"]).astype(int)
    result_df["ì´ê²©ë„"] = (result_df["close"] / result_df["ma20"] - 1) * 100
    result_df["ìˆ˜ìµë¥ "] = result_df["close"].pct_change()
    result_df["ë³€ë™ì„±"] = result_df["ìˆ˜ìµë¥ "].rolling(window=20).std() * (20 ** 0.5)
    result_df["ROC"] = calculate_roc(result_df["close"], period=12)
    result_df["RSI"] = calculate_rsi(result_df["close"])

    return result_df.reset_index(drop=True)



def log_backtest_debug(name, df, result, initial_capital, buy_discount, sell_premium):
    print(f"\nğŸ“˜ [ë””ë²„ê·¸: {name}]")
    print(f"  - ì‹œì‘ì¼: {df['date'].iloc[0].date()}, ì¢…ë£Œì¼: {df['date'].iloc[-1].date()}")
    print(f"  - ì´ˆê¸° ìë³¸: ${initial_capital:,.0f}")
    print(f"  - ë§¤ìˆ˜ ê¸°ì¤€ (discount): {buy_discount * 100:.2f}%, ë§¤ë„ ê¸°ì¤€ (premium): {sell_premium * 100:.2f}%")
    print(f"  - ìˆ˜ìµë¥ : {result['ìˆ˜ìµë¥ ']}%, MDD: {result['MDD']}%")


# âœ… TierPosition í´ë˜ìŠ¤ ì •ì˜
class TierPosition:
    def __init__(self, tier_index, weight, capital):
        self.tier_index = tier_index           # í‹°ì–´ ë²ˆí˜¸
        self.weight = weight                   # ë¹„ì¤‘ (ê°€ì¤‘ì¹˜)
        self.initial_cash = capital            # ì´ˆê¸° ìê¸ˆ
        self.cash = capital                    # í˜„ì¬ ë³´ìœ  í˜„ê¸ˆ
        self.reset()

    def reset(self):
        self.active = False                    # í˜„ì¬ í¬ì§€ì…˜ ë³´ìœ  ì—¬ë¶€
        self.buy_price = None                  # ë§¤ìˆ˜ ê°€ê²©
        self.shares = 0                        # ë³´ìœ  ì£¼ì‹ ìˆ˜
        self.hold_days = 0                     # ë³´ìœ  ì¼ìˆ˜
        self.entry_date = None                 # ë§¤ìˆ˜ ë‚ ì§œ

    def try_buy(self, trigger_price, actual_close, date):
        trigger_price = round(trigger_price, 2)
        actual_close = round(actual_close, 2)
        if actual_close > trigger_price:
            return False
        # shares = int(self.cash // actual_close)
        shares = int(self.initial_cash // trigger_price)
        if shares == 0:
            return False
        cost = shares * actual_close
        self.active = True
        self.buy_price = actual_close
        self.shares = shares
        self.hold_days = 0
        self.entry_date = date
        self.cash -= cost
        return True

    def update_holding(self):
        if self.active:
            self.hold_days += 1

    def try_sell(self, price, date, sell_premium):
        price = round(price, 2)
        if self.active and price >= round(self.buy_price * (1 + sell_premium), 2):
            proceeds = self.shares * price
            self.cash += proceeds
            self.reset()
            return True
        return False

    def force_sell(self, price, date):
        price = round(price, 2)
        if self.active:
            proceeds = self.shares * price
            self.cash += proceeds
            self.reset()
            return True
        return False

# âœ… TTL ì „ëµ ì‹¤í–‰ í•¨ìˆ˜
def run_simple_ttl_backtest(df, tier_weights, initial_capital=10000, hold_days_limit=10,
                            buy_discount=0.0001, sell_premium=0.0001):
    TIERS = len(tier_weights)
    tier_initials = [initial_capital * w for w in tier_weights]
    tier_positions = [TierPosition(i, tier_weights[i], tier_initials[i]) for i in range(TIERS)]

    high_watermark = initial_capital
    records = []

    for i in range(len(df)):
        today = df.loc[i, "date"]
        close = round(df.loc[i, "close"], 2)
        prev_close = round(df.loc[i - 1, "close"], 2) if i > 0 else close
        did_profit_sell_today = False

        for pos in tier_positions:
            if pos.active:
                if pos.try_sell(close, today, sell_premium):
                    did_profit_sell_today = True
                else:
                    pos.update_holding()

        for pos in tier_positions:
            if pos.active and pos.hold_days >= hold_days_limit:
                pos.force_sell(close, today)

        if i > 0 and not did_profit_sell_today:
            for pos in tier_positions:
                if not pos.active:
                    target_price = round(prev_close * (1 - buy_discount), 2)
                    if pos.try_buy(target_price, close, today):
                        break

        valuation = sum([pos.shares * close for pos in tier_positions])
        total_cash = sum([pos.cash for pos in tier_positions])
        total_value = valuation + total_cash
        high_watermark = max(high_watermark, total_value)
        drawdown = (total_value - high_watermark) / high_watermark

        records.append({
            "date": today,
            "portfolio_value": total_value,
            "drawdown": drawdown
        })
        
        # # âœ… ìƒíƒœ ë¡œê·¸ ì¶œë ¥ (ë§¤ì¼)
        # tier_statuses = [f"í‹°ì–´{pos.tier_index}: ${round(pos.cash + pos.shares * close)}" for pos in tier_positions]
        # tier_summary = ", ".join(tier_statuses)
        # print(f"ğŸ“… {today.date()} | {tier_summary} | ì´ ìì‚°: ${round(total_value)} | DD: {round(drawdown * 100, 2)}%")


    start_value = records[0]["portfolio_value"]
    end_value = records[-1]["portfolio_value"]
    max_drawdown = min([r["drawdown"] for r in records])

    # # âœ… ë¡œê·¸ ì¶œë ¥
    # start_date = df["date"].iloc[0]
    # end_date = df["date"].iloc[-1]
    # print(f"ğŸ§ª [ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œê·¸] ê¸°ê°„: {start_date.date()} ~ {end_date.date()}, ìˆ˜ìµë¥ : {round((end_value - start_value) / start_value * 100, 2)}%")

    return {
        "ìˆ˜ìµë¥ ": round((end_value - start_value) / start_value * 100, 1),
        "MDD": round(max_drawdown * 100, 1),
        "ê¸°ë¡": records  # ë‚˜ì¤‘ì— ì‹œê°í™”ìš©
    }

from datetime import timedelta
import pandas as pd

def run_one_rolling_test(price_df, all_dates, i, test_days,
                         PRO1_WEIGHTS, PRO2_WEIGHTS, PRO3_WEIGHTS,
                         run_simple_ttl_backtest):

    test_start = all_dates[i]
    test_end_est = test_start + timedelta(days=test_days - 1)
    test_end_index = price_df.index.get_indexer([test_end_est], method='bfill')[0]
    if test_end_index == -1:
        return None
    test_end = price_df.index[test_end_index]

    ma_window = 60
    extended_start_index = max(0, i - ma_window)
    extended_range = price_df.iloc[extended_start_index:test_end_index + 1]
    test_range = price_df.loc[test_start:test_end]

    extended_range = extended_range.reset_index()
    test_df = test_range.reset_index()

    result1 = run_simple_ttl_backtest(test_df, PRO1_WEIGHTS)
    result2 = run_simple_ttl_backtest(test_df, PRO2_WEIGHTS)
    result3 = run_simple_ttl_backtest(test_df, PRO3_WEIGHTS)

    scores = {
        "Pro1": result1["ìˆ˜ìµë¥ "] - 0.75 * abs(result1["MDD"]),
        "Pro2": result2["ìˆ˜ìµë¥ "] - 0.75 * abs(result2["MDD"]),
        "Pro3": result3["ìˆ˜ìµë¥ "] - 0.75 * abs(result3["MDD"])
    }

    best_strategy = max(scores, key=scores.get)

    return {
        "ì‹œì‘ì¼": test_start.date(),
        "ì¢…ë£Œì¼": test_end.date(),
        "Pro1_ìˆ˜ìµë¥ ": result1["ìˆ˜ìµë¥ "],
        "Pro1_mdd": result1["MDD"],
        "Pro2_ìˆ˜ìµë¥ ": result2["ìˆ˜ìµë¥ "],
        "Pro2_mdd": result2["MDD"],
        "Pro3_ìˆ˜ìµë¥ ": result3["ìˆ˜ìµë¥ "],
        "Pro3_mdd": result3["MDD"],
        "ìš°ìˆ˜í•œì „ëµ": best_strategy
    }

def run_daily_rolling_backtest(price_df: pd.DataFrame, start_date: str, test_days: int):
    from .backtest import run_simple_ttl_backtest

    PRO1_WEIGHTS = [0.05, 0.10, 0.15, 0.20, 0.25, 0.25]
    PRO2_WEIGHTS = [0.10, 0.15, 0.20, 0.25, 0.20, 0.10]
    PRO3_WEIGHTS = [1/6] * 6

    price_df = price_df.copy()
    price_df["date"] = pd.to_datetime(price_df["date"])
    price_df = price_df.drop_duplicates(subset="date").set_index("date").sort_index()

    all_dates = price_df.index
    start_idx = all_dates.get_indexer([pd.to_datetime(start_date)], method='bfill')[0]

    results = []
    for i in range(start_idx, len(all_dates)):
        result = run_one_rolling_test(
            price_df, all_dates, i, test_days,
            PRO1_WEIGHTS, PRO2_WEIGHTS, PRO3_WEIGHTS,
            run_simple_ttl_backtest
        )
        if result is not None:
            results.append(result)

    return pd.DataFrame(results)
